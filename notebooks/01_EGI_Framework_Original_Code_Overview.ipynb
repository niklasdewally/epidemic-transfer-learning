{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b24963e4",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-0\"><span class=\"toc-item-num\">0&nbsp;&nbsp;</span>Introduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Some-Setup\" data-toc-modified-id=\"Some-Setup-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>Some Setup</a></span></li></ul></li><li><span><a href=\"#The-Airport-Dataset\" data-toc-modified-id=\"The-Airport-Dataset-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>The Airport Dataset</a></span></li><li><span><a href=\"#Data-Preparation\" data-toc-modified-id=\"Data-Preparation-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Preparation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Conversion-to-DGL\" data-toc-modified-id=\"Conversion-to-DGL-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Conversion to DGL</a></span></li><li><span><a href=\"#Creation-of-training-and-test-sets\" data-toc-modified-id=\"Creation-of-training-and-test-sets-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Creation of training and test sets</a></span></li></ul></li><li><span><a href=\"#Generation-of-k-hop-ego-graphs\" data-toc-modified-id=\"Generation-of-k-hop-ego-graphs-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Generation of k-hop-ego-graphs</a></span><ul class=\"toc-item\"><li><span><a href=\"#A-look-at-some-specific-ego-graphs\" data-toc-modified-id=\"A-look-at-some-specific-ego-graphs-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>A look at some specific ego-graphs</a></span></li></ul></li><li><span><a href=\"#The-Encoder-and-Discriminator\" data-toc-modified-id=\"The-Encoder-and-Discriminator-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>The Encoder and Discriminator</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Training</a></span></li><li><span><a href=\"#Transfer-learning\" data-toc-modified-id=\"Transfer-learning-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Transfer learning</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0146782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to disable plotting - speeds up execution time!\n",
    "plot_graphs = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efa60f7",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "The aim of this notebook is to give an overview of the EGI framework.\n",
    "\n",
    "This notebook primarily runs through the `run_airport.py` experiment.\n",
    "\n",
    "\n",
    "![Figure 2, taken from (Transfer Learning of Graph Neural Networks with Ego-graph Information Maximization, Zhu et al, 2021)](figures/fig2.png)\n",
    "\n",
    "\n",
    "The code in this notebook is taken largely from the original code, however modifications have been made for readability and compatability.\n",
    "\n",
    "The code is archived at https://github.com/niklasdewally/EGI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f9fabc",
   "metadata": {},
   "source": [
    "## Some Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b761b33",
   "metadata": {},
   "source": [
    "Check if the GPU works.\n",
    "\n",
    "This code should work on any CUDA 11 compatible GPU, but has been written and tested on a 3060 only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "264ba1c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\r\n",
      "Built on Sun_Aug_15_21:14:11_PDT_2021\r\n",
      "Cuda compilation tools, release 11.4, V11.4.120\r\n",
      "Build cuda_11.4.r11.4/compiler.30300941_0\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bc17acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../egi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "874dc8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import argparse, time\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import dgl\n",
    "from dgl import DGLGraphStale as DGLGraph\n",
    "from dgl.data import register_data_args, load_data\n",
    "\n",
    "from models.dgi import DGI, MultiClassifier\n",
    "from  models.subgi import GNNDiscLayer,GIN\n",
    "from models.utils import *\n",
    "\n",
    "from IPython import embed\n",
    "import scipy.sparse as sp\n",
    "from collections import defaultdict\n",
    "from torch.autograd import Variable\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "from types import SimpleNamespace\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e741c89",
   "metadata": {},
   "source": [
    "# The Airport Dataset\n",
    "\n",
    "This notebook uses the provided airport data set that links airports that fly to eachother with edges, and labels airports based on their relative popularity.\n",
    "\n",
    "The USA is used for the training and test sets, and Brazil for validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a09e6d",
   "metadata": {},
   "source": [
    "The source of this data is the paper `struc2vec: Learning Node Representations from Structural Identity (Ribeiro et al)`\n",
    "    \n",
    "    \n",
    "> Airports will be assigned a label corresponding to their level of activity, measured in flights or people (discussed below). \n",
    "    > We consider the following datasets (collected for this study):\n",
    "    >\n",
    "    >Brazilian air-traffc network: Data collected from the National Civil Aviation Agency (ANAC)1 from January to December 2016.\n",
    "    >   The network has 131 nodes, 1,038 edges (diameter is 5). \n",
    "    > Airport activity is measured by the total number of landings plus takeoffs in the corresponding year.\n",
    "    >   \n",
    "    > American air-traffic network: Data collected from the Bureau of Transportation Statistics2 from January to October, 2016.\n",
    "    >   The e network has 1,190 nodes, 13,599 edges (diameter is 8). \n",
    "    >   Airport activity is measured by the total number of people that passed (arrived plus departed) the airport in the corresponding period. \n",
    "    >    \n",
    "    > European air-traffic network: Data collected from the Statistical Office of the European Union (Eurostat)3 from January to November 2016. \n",
    "    > The e network has 399 nodes, 5,995 edges (diameter is 5).\n",
    "    > Airport activity is measured by the total number of landings plus takeoffs in the corresponding period.\n",
    "    >\n",
    "    > For each airport, we assign one of four possible labels corresponding to their activity.\n",
    "    > In particular, for each dataset, we use the quartiles obtained from the empirical activity distribution to split the dataset in four groups, assigning a different label for each group. \n",
    "    > Thus, label 1 is given to the 25% less active airports, and so on. \n",
    "    >Note that all classes (labels) have the same size (number of airports).\n",
    "    > Moreover, classes are related more to the role played by the airport."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc6cac0",
   "metadata": {},
   "source": [
    "**First, set some options for the model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dff714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = SimpleNamespace(\n",
    "    edge_path = \"../../egi/data/usa-airports.edgelist\",\n",
    "    label_path=\"../../egi/data/labels-usa-airports.txt\",\n",
    "    data_src=\"\",\n",
    "    data_id=\"\",\n",
    "    gpu=0,\n",
    "    model_id=2,\n",
    "    dropout=0.0,\n",
    "    dgi_lr=0.001,\n",
    "    classifier_lr=1e-2,\n",
    "    n_dgi_epochs=100,\n",
    "    n_classifier_epochs=100,\n",
    "    n_hidden=32,\n",
    "    n_layers=2,\n",
    "    weight_decay=0.,\n",
    "    patience=20,\n",
    "    model=True,\n",
    "    self_loop=True,\n",
    "    model_type=2,\n",
    "    graph_type=\"DD\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c7b4bf",
   "metadata": {},
   "source": [
    "* * * \n",
    "**A quick look at the input data:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c8e23b",
   "metadata": {},
   "source": [
    "The edge list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "304501ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12343 12129\r\n",
      "13277 11996\r\n",
      "13796 13476\r\n",
      "15061 14559\r\n",
      "14314 12889\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 \"../../egi/data/usa-airports.edgelist\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73151488",
   "metadata": {},
   "source": [
    "The node labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a76a8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node label\r\n",
      "10241 1\r\n",
      "10243 2\r\n",
      "10245 0\r\n",
      "16390 1\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 \"../../egi/data/labels-usa-airports.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1423c1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68574779",
   "metadata": {},
   "source": [
    "**Now, read in the dataset as a NetworkX graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99f656d3",
   "metadata": {
    "code_folding": [
     22
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read in a graph from a given edge list and node label list.\n",
    "\n",
    "\n",
    "edge_path: A file containing edges. This must be in the form:\n",
    "    <int> <int>\n",
    "    <int> <int>\n",
    "\n",
    "    where each line contains the integer IDs of the nodes on each edge.\n",
    "    \n",
    "    \n",
    "label_path: A file containing node labels. This must be in the form:\n",
    "    <int> <string>\n",
    "    <int> <string>\n",
    "\n",
    "    where each line contains the integer ID of a node, followed by its label.\n",
    "    \n",
    "    \n",
    "    \n",
    "Returns: a networkx graph, and a dictionary of labels.\n",
    "\n",
    "\"\"\"\n",
    "def read_graph(edge_path,label_path):\n",
    "    g = nx.Graph()\n",
    "    \n",
    "    with open(edge_path) as IN:\n",
    "        for line in IN:\n",
    "            tmp = line.strip().split()\n",
    "            g.add_edge(int(tmp[0]), int(tmp[1]))\n",
    "    labels = dict()\n",
    "    with open(label_path) as IN:\n",
    "        IN.readline()\n",
    "        for line in IN:\n",
    "            tmp = line.strip().split(' ')\n",
    "            labels[int(tmp[0])] = int(tmp[1])\n",
    "    return g, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "382ba9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 1190 nodes and 13599 edges\n"
     ]
    }
   ],
   "source": [
    "g,labels = read_graph(opts.edge_path,opts.label_path)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e48ddb6",
   "metadata": {
    "code_folding": [
     10
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot and show a given airport graph. \n",
    "\n",
    "Colours the graph according to airport popularity.\n",
    "\n",
    "G : The airport graph\n",
    "labels: a map of node ids to labels\n",
    "\n",
    "Returns: None\n",
    "\"\"\"\n",
    "def plot_airport_graph(G,labels):\n",
    "    if not plot_graphs:\n",
    "        return\n",
    "    # adapted from https://plotly.com/python/network-graphs/\n",
    "    \n",
    "    # give the nodes positions\n",
    "    positions = nx.spring_layout(G)\n",
    "    \n",
    "    edge_x = []\n",
    "    edge_y = []\n",
    "    for edge in G.edges():\n",
    "        x0, y0 = positions[edge[0]]\n",
    "        x1, y1 = positions[edge[1]]\n",
    "        edge_x.append(x0)\n",
    "        edge_x.append(x1)\n",
    "        edge_x.append(None)\n",
    "        edge_y.append(y0)\n",
    "        edge_y.append(y1)\n",
    "        edge_y.append(None)\n",
    "\n",
    "    edge_trace = go.Scatter(\n",
    "        x=edge_x, y=edge_y,\n",
    "        line=dict(width=0.5, color='#888'),\n",
    "        hoverinfo='none',\n",
    "        mode='lines')\n",
    "\n",
    "    node_x = []\n",
    "    node_y = []\n",
    "    for node in G.nodes():\n",
    "        x, y = positions[node]\n",
    "        node_x.append(x)\n",
    "        node_y.append(y)\n",
    "\n",
    "    node_trace = go.Scatter(\n",
    "        x=node_x, y=node_y,\n",
    "        mode='markers',\n",
    "        hoverinfo='text',\n",
    "        marker=dict(\n",
    "            showscale=True,\n",
    "            # colorscale options\n",
    "            #'Greys' | 'YlGnBu' | 'Greens' | 'YlOrRd' | 'Bluered' | 'RdBu' |\n",
    "            #'Reds' | 'Blues' | 'Picnic' | 'Rainbow' | 'Portland' | 'Jet' |\n",
    "            #'Hot' | 'Blackbody' | 'Earth' | 'Electric' | 'Viridis' |\n",
    "            colorscale='YlGnBu',\n",
    "            reversescale=True,\n",
    "            color=[],\n",
    "            size=10,\n",
    "            colorbar=dict(\n",
    "                thickness=15,\n",
    "                title='Airport popularity',\n",
    "                xanchor='left',\n",
    "                titleside='right'\n",
    "            ),\n",
    "            line_width=2))\n",
    "    \n",
    "    node_popularity = []\n",
    "    for node in G.nodes():\n",
    "        node_popularity.append(labels.get(node,0))\n",
    "        \n",
    "    node_trace.marker.color = node_popularity\n",
    "    \n",
    "    fig = go.Figure(data=[edge_trace, node_trace],\n",
    "             layout=go.Layout(\n",
    "                showlegend=False,\n",
    "                hovermode='closest',\n",
    "                margin=dict(b=20,l=5,r=5,t=40),\n",
    "                annotations=[ dict(\n",
    "                    text=\"The airports network\",\n",
    "                    showarrow=False,\n",
    "                    xref=\"paper\", yref=\"paper\",\n",
    "                    x=0.005, y=-0.002 ) ],\n",
    "                xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
    "                )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14f4d17e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_airport_graph(g,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44419bd0",
   "metadata": {},
   "source": [
    "**The aim is to direct-transfer the node labels from this graph onto another with a different topology.**\n",
    "\n",
    "In this case, this will be the Brazil dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d351377",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "validation_g,validation_labels = read_graph(\"../../egi/data/brazil-airports.edgelist\",\n",
    "                                            \"../../egi/data/labels-brazil-airports.txt\")\n",
    "plot_airport_graph(validation_g,{})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395b4c30",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d8ce0e",
   "metadata": {},
   "source": [
    "Remove self-loops from the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad3aa2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.remove_edges_from(nx.selfloop_edges(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475edaa0",
   "metadata": {},
   "source": [
    "## Conversion to DGL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feba518b",
   "metadata": {},
   "source": [
    "The graph needs to be converted to a `DGL` graph, and the labels to a `Tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e82c178",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Convert the graph from a NetworkX graph into a DGL graph.\n",
    "\n",
    "graph: a networkx graph\n",
    "labels: a dictionary mapping node IDs to labels\n",
    "\n",
    "\n",
    "Returns: a tuple of:\n",
    "    graph: the graph, as a DGL graph.\n",
    "    labels: the labels, as a LongTensor .\n",
    "    \n",
    "\"\"\"\n",
    "def construct_DGL(graph, labels):\n",
    "    node_mapping = defaultdict(int)\n",
    "    \n",
    "    relabels = []\n",
    "    for node in sorted(list(graph.nodes())):\n",
    "        node_mapping[node] = len(node_mapping)\n",
    "        relabels.append(labels[node])\n",
    "\n",
    "    assert len(node_mapping) == len(labels)\n",
    "    \n",
    "    new_g = DGLGraph()\n",
    "    new_g.add_nodes(len(node_mapping))\n",
    "    \n",
    "    for i in range(len(node_mapping)):\n",
    "        new_g.add_edge(i, i)\n",
    "    for edge in graph.edges():\n",
    "        new_g.add_edge(node_mapping[edge[0]], node_mapping[edge[1]])\n",
    "        new_g.add_edge(node_mapping[edge[1]], node_mapping[edge[0]])\n",
    "        \n",
    "    # convert labels to tensor\n",
    "    relabels = torch.LongTensor(relabels)\n",
    "    return new_g, relabels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de590d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "g, labels = construct_DGL(g, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e596526",
   "metadata": {},
   "source": [
    "## Creation of training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79030913",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Partition the labels into training and test sets.\n",
    "\n",
    "labels: a LongTensor of labels to partition into training and test sets.\n",
    "\n",
    "valid_mask: ???\n",
    "\n",
    "train_ratio: the proportion of data to use as training data.\n",
    "    Default: 0.8\n",
    "    \n",
    "Returns: a tuple containing a training mask and a test mask. These are both BoolTensors.\n",
    "\"\"\"\n",
    "def createTraining(labels, valid_mask = None, train_ratio=0.8):\n",
    " \n",
    "    train_mask = torch.zeros(labels.shape, dtype=torch.bool)\n",
    "    test_mask = torch.ones(labels.shape, dtype=torch.bool)\n",
    "    \n",
    "    num_train = int(labels.shape[0] * train_ratio)\n",
    "    all_node_index = list(range(labels.shape[0]))\n",
    "    np.random.shuffle(all_node_index)\n",
    "    #for i in range(len(idx) * train_ratio):\n",
    "    # embed()\n",
    "    train_mask[all_node_index[:num_train]] = 1\n",
    "    test_mask[all_node_index[:num_train]] = 0\n",
    "    if valid_mask is not None:\n",
    "        train_mask *= valid_mask\n",
    "        test_mask *= valid_mask\n",
    "        \n",
    "    return torch.BoolTensor(train_mask), torch.BoolTensor(test_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e8caad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask, test_mask = createTraining(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd92747",
   "metadata": {},
   "source": [
    "# Generation of k-hop-ego-graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0353d0",
   "metadata": {},
   "source": [
    "The set of all sampled k-hop-ego-graphs is represented as a `NodeFlow`.\n",
    "\n",
    "In a `NodeFlow`, the set of edges between layers is known as a `block`.\n",
    "\n",
    "Layers contain the nodes reachable from the seed nodes after a certain number of hops.\n",
    "\n",
    "What `opt` calls `n_layers` is the `k` number used in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646f684f",
   "metadata": {},
   "source": [
    "![The NodeFlow object (source https://github.com/dmlc/dgl/issues/368)](figures/nodeflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ca2085",
   "metadata": {},
   "source": [
    "* * *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f614dedc",
   "metadata": {},
   "source": [
    "The following code can be used to sample k-hop ego-graphs from the graph.\n",
    "For visualisation purposes, consider a small k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23ea6621",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = opts.n_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf09ddbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/dgl/base.py:45: DGLWarning: dgl.contrib.sampling.NeighborSampler is deprecated starting from v0.5. Please read our guide<link> for how to use the new sampling APIs.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "g.readonly() # A readonly DGL graph is required for sampling.\n",
    "\n",
    "\n",
    "# https://docs.dgl.ai/en/0.2.x/api/python/sampler.html\n",
    "sampler = dgl.contrib.sampling.NeighborSampler(g, 256, 5,\n",
    "                                               neighbor_type='in', num_workers=1,\n",
    "                                               num_hops=k, shuffle=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa209a9",
   "metadata": {},
   "source": [
    "## A look at some specific ego-graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6d94fa",
   "metadata": {},
   "source": [
    "First, get a list of all edges in the ego graph for some `start` node, alongside their block number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e2d332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges_from_flow(node_flow,start,k):\n",
    "    edges = []\n",
    "    if k==0:\n",
    "        return None\n",
    "    \n",
    "    for next_node in node_flow.successors(start):\n",
    "        next_node = next_node.item()\n",
    "        edges += [[k,start,next_node]]\n",
    "        a = get_edges_from_flow(node_flow,next_node,k-1)\n",
    "        if a is not None:\n",
    "            edges += a\n",
    "    \n",
    "    return edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36736ffd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/dgl/base.py:45: DGLWarning: NodeFlow APIs are deprecated starting from v0.5. Please read our guide<link> for how to use the new sampling APIs.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "node_flow = sampler.fetch(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7331c4cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 1, 785], [1, 785, 1403], [2, 1, 975], [1, 975, 1520], [1, 975, 1529]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_edges_from_flow(node_flow,1,k)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65f6280",
   "metadata": {},
   "source": [
    "Now, visualise the ego-graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3483b0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot and show a given ego-graph. \n",
    "\n",
    "Colours the graph according to n-hops from the centre.\n",
    "\n",
    "nf: The nodeflow representing all possible ego-graphs\n",
    "start: the node to visualise the ego_graph of\n",
    "k: \n",
    "\n",
    "Returns: None\n",
    "\"\"\"\n",
    "def plot_ego_graph(nf,start,k):\n",
    "    if not plot_graphs:\n",
    "        return\n",
    "\n",
    "    # adapted from https://plotly.com/python/network-graphs/\n",
    "    edges = get_edges_from_flow(nf,start,k)\n",
    "    \n",
    "    # First, convert to networkX\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add the start node in the centre\n",
    "    G.add_node(start,pos=[0,0]) \n",
    "    colours = [0]\n",
    "    \n",
    "    # Add nodes, and store colours\n",
    "    # For now, just colour the centre\n",
    "    # Do this before edges so colour and nodes are the same ordering\n",
    "    for colour,src,dest in edges:\n",
    "        colours += [5]\n",
    "        G.add_node(dest)\n",
    "    \n",
    "    \n",
    "    for _,src,dest in edges:\n",
    "        G.add_edge(src,dest)\n",
    "        \n",
    "    \n",
    "    # give the nodes positions\n",
    "    positions = nx.spring_layout(G,center=[0,0])\n",
    "    \n",
    "    edge_x = []\n",
    "    edge_y = []\n",
    "    for edge in G.edges():\n",
    "        x0, y0 = positions[edge[0]]\n",
    "        x1, y1 = positions[edge[1]]\n",
    "        edge_x.append(x0)\n",
    "        edge_x.append(x1)\n",
    "        edge_x.append(None)\n",
    "        edge_y.append(y0)\n",
    "        edge_y.append(y1)\n",
    "        edge_y.append(None)\n",
    "\n",
    "    edge_trace = go.Scatter(\n",
    "        x=edge_x, y=edge_y,\n",
    "        line=dict(width=0.5, color='#888'),\n",
    "        hoverinfo='none',\n",
    "        mode='lines')\n",
    "\n",
    "    node_x = []\n",
    "    node_y = []\n",
    "    for node in G.nodes():\n",
    "        x, y = positions[node]\n",
    "        node_x.append(x)\n",
    "        node_y.append(y)\n",
    "\n",
    "    node_trace = go.Scatter(\n",
    "        x=node_x, y=node_y,\n",
    "        mode='markers',\n",
    "        hoverinfo='text',\n",
    "        marker=dict(\n",
    "            showscale=True,\n",
    "            # colorscale options\n",
    "            #'Greys' | 'YlGnBu' | 'Greens' | 'YlOrRd' | 'Bluered' | 'RdBu' |\n",
    "            #'Reds' | 'Blues' | 'Picnic' | 'Rainbow' | 'Portland' | 'Jet' |\n",
    "            #'Hot' | 'Blackbody' | 'Earth' | 'Electric' | 'Viridis' |\n",
    "            colorscale='YlGnBu',\n",
    "            reversescale=True,\n",
    "            color=[],\n",
    "            size=10,\n",
    "            colorbar=dict(\n",
    "                thickness=15,\n",
    "                title='Ego Graph',\n",
    "                xanchor='left',\n",
    "                titleside='right'\n",
    "            ),\n",
    "            line_width=2))\n",
    "\n",
    "        \n",
    "    node_trace.marker.color = colours\n",
    "    \n",
    "    fig = go.Figure(data=[edge_trace, node_trace],\n",
    "             layout=go.Layout(\n",
    "                showlegend=False,\n",
    "                hovermode='closest',\n",
    "                margin=dict(b=20,l=5,r=5,t=40),\n",
    "                annotations=[ dict(\n",
    "                    text=\"An egograph\",\n",
    "                    showarrow=False,\n",
    "                    xref=\"paper\", yref=\"paper\",\n",
    "                    x=0.005, y=-0.002 ) ],\n",
    "                xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
    "                )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6ddeb35",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_ego_graph(node_flow,1,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e14beae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ego_graph(node_flow,2,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f206c115",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_ego_graph(node_flow,20,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98533b3",
   "metadata": {},
   "source": [
    "# The Encoder and Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc60bd9",
   "metadata": {},
   "source": [
    "*The below code has been adapted from `models/dgi.py`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf50cac6",
   "metadata": {},
   "source": [
    "The encoder is trained as a GAN. It produces both real (positive) and fake (negative) node embeddings for a discriminator which then tries to guess which is which."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28a8ca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, g, in_feats, n_hidden, n_layers, activation, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.g = g\n",
    "        self.conv = GIN(g, n_layers + 1, 1, in_feats, n_hidden, n_hidden, dropout, True, 'sum', 'sum')\n",
    "\n",
    "    def forward(self, features, corrupt=False):\n",
    "        if corrupt:\n",
    "            perm = torch.randperm(self.g.number_of_nodes())\n",
    "            features = features[perm]\n",
    "        features = self.conv(features)\n",
    "        return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a8a05d",
   "metadata": {},
   "source": [
    "The corrupt flag of `forward()` is used to generate the fake output (the *negative ego graph*).\n",
    "\n",
    "This is the EGI discriminator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08154c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubGDiscriminator(nn.Module):\n",
    "    def __init__(self, g, in_feats, n_hidden, n_layers = 2):\n",
    "        super(SubGDiscriminator, self).__init__()\n",
    "        self.g = g\n",
    "        \n",
    "        self.dc_layers = nn.ModuleList()\n",
    "        \n",
    "        for i in range(n_layers):\n",
    "            self.dc_layers.append(GNNDiscLayer(in_feats, n_hidden))\n",
    "        \n",
    "        self.linear = nn.Linear(in_feats + 2 * n_hidden, n_hidden, bias = True)\n",
    "        self.in_feats = in_feats\n",
    "        self.U_s = nn.Linear(n_hidden, 1)\n",
    "\n",
    "        \n",
    "    def edge_output(self, edges):\n",
    "        return {'h': torch.cat([edges.src['root'], edges.src['m'], edges.dst['x']], dim=1)}\n",
    "\n",
    "    def find_common(self, layer_nid, nf):\n",
    "        reverse_nodes = set()\n",
    "        for i in range(nf.num_blocks):\n",
    "            u, v = self.g.find_edges(nf.block_parent_eid(i))\n",
    "            reverse_nodes.update(u.tolist())\n",
    "            reverse_nodes.update(v.tolist())\n",
    "            \n",
    "        layer_nid = set(layer_nid.tolist())\n",
    "        \n",
    "        return torch.tensor(list(layer_nid.intersection(reverse_nodes)))\n",
    "\n",
    "    def forward(self, nf, emb, features):\n",
    "        reverse_edges = []\n",
    "        for i in range(nf.num_blocks):\n",
    "\n",
    "            u,v = self.g.find_edges(nf.block_parent_eid(i))\n",
    "            reverse_edges += self.g.edge_ids(v,u).numpy().tolist()\n",
    "            \n",
    "            \n",
    "        small_g = self.g.edge_subgraph( reverse_edges)\n",
    "        small_g.ndata['root'] = emb[small_g.ndata['_ID']]\n",
    "        small_g.ndata['x'] = features[small_g.ndata['_ID']]\n",
    "        small_g.ndata['m']= torch.zeros_like(emb[small_g.ndata['_ID']])\n",
    "\n",
    "        edge_embs = []\n",
    "        for i in range(nf.num_blocks)[::-1]:\n",
    "\n",
    "            v = small_g.map_to_subgraph_nid(nf.layer_parent_nid(i+1))\n",
    "\n",
    "            uid = small_g.out_edges(v, 'eid')\n",
    "\n",
    "            if i+1 == nf.num_blocks:\n",
    "                h = self.dc_layers[0](small_g, v, uid, 1)\n",
    "            else:\n",
    "                h = self.dc_layers[0](small_g, v, uid, 2)\n",
    "\n",
    "            edge_embs.append(self.U_s(F.relu(self.linear(h))))\n",
    "        return edge_embs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b2742f",
   "metadata": {},
   "source": [
    "These are trained together as a GAN like so:\n",
    "    \n",
    "This example considers the `SubGI` version of the model, but other versions are also given:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5559281",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubGI(nn.Module):\n",
    "    def __init__(self, g, in_feats, n_hidden, n_layers, activation, dropout, pretrain=None):\n",
    "        super(SubGI, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(g, in_feats, n_hidden, n_layers, activation, dropout)\n",
    "       \n",
    "        self.g = g\n",
    "\n",
    "        self.subg_disc = SubGDiscriminator(g, in_feats, n_hidden) # Discriminator\n",
    "        \n",
    "        self.loss = nn.BCEWithLogitsLoss()\n",
    "        self.in_feats = in_feats\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_layers = n_layers\n",
    "        self.activation = activation\n",
    "        self.dropout = dropout\n",
    "        if pretrain is not None:\n",
    "            print(\"Loaded pre-train model: {}\".format(pretrain) )\n",
    "            self.load_state_dict(torch.load(pretrain))\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        self.encoder = Encoder(self.g, self.in_feats, self.n_hidden, self.n_layers, self.activation, self.dropout)\n",
    "        self.encoder.conv.g = self.g\n",
    "        self.subg_disc = SubGDiscriminator(self.g, self.in_feats, self.n_hidden, self.model_id)\n",
    "        self.loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, features, nf):\n",
    "        positive = self.encoder(features, corrupt=False)\n",
    "        \n",
    "        perm = torch.randperm(self.g.number_of_nodes())\n",
    "        negative = positive[perm]\n",
    "\n",
    "\n",
    "        positive_batch = self.subg_disc(nf, positive, features)\n",
    "\n",
    "        negative_batch = self.subg_disc(nf, negative, features)\n",
    "\n",
    "        E_pos, E_neg, l = 0.0, 0.0, 0.0\n",
    "        pos_num, neg_num = 0, 0\n",
    "        \n",
    "        for positive_edge, negative_edge in zip(positive_batch, negative_batch):\n",
    "\n",
    "            E_pos += get_positive_expectation(positive_edge, 'JSD', average=False).sum()\n",
    "            pos_num += positive_edge.shape[0]\n",
    "\n",
    "            E_neg += get_negative_expectation(negative_edge, 'JSD', average=False).sum()\n",
    "            neg_num += negative_edge.shape[0]\n",
    "\n",
    "            l += E_neg - E_pos\n",
    "\n",
    "        return E_neg / neg_num - E_pos / pos_num\n",
    "    \n",
    "    # TODO: this was never actually fully implemented?\n",
    "    def train_model(self):\n",
    "        self.train()\n",
    "        cur_loss = []\n",
    "        \n",
    "        for nf in self.train_sampler:\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            l = self.forward(self.features, nf)\n",
    "            l.backward()\n",
    "            cur_loss.append(l.item())\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "        return np.mean(cur_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec0b432",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb05eda3",
   "metadata": {},
   "source": [
    "Training occurs in two parts. First a model is trained to encode the graph in such a way that it's structural info is retained. Then, a classifier is trained on this encoding and the node labels.\n",
    "\n",
    "These two parts of the model are entirely seperate - the encoder, once trained, could then be used as part of link prediction or other graph learning tasks.\n",
    "\n",
    "* * * \n",
    "\n",
    "The features given as input are node degrees, but can be other node specific features such as PageRank scores, spectral-embeddings, etc. These should be a function of the graph structure - i.e. sensitive to changes in the graph structures.\n",
    "\n",
    "The encoder is also given the ego-graphs during training, but is only ran on node features at evaluation-time.\n",
    "\n",
    "\n",
    "After embedding the graph, the node classifications (1-4) are used to train the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afc47962",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For a given graph, create a tensor of nodes to node degrees.\n",
    "\n",
    "graph: A DGL graph\n",
    "opts: The model options\n",
    "\n",
    "Return: a Tensor with the shape (number_of_nodes,max_degree). \n",
    "\n",
    "    For a node n with degree d, this tensor contains a 1 \n",
    "    in position feature[n][d], and a 0 otherwise.\n",
    "....\n",
    "\"\"\"\n",
    "def degree_bucketing(graph, opts, degree_emb=None, max_degree = 10):\n",
    "    \n",
    "    max_degree = opts.n_hidden\n",
    "    features = torch.zeros([graph.number_of_nodes(), max_degree])\n",
    "\n",
    "    for i in range(graph.number_of_nodes()):\n",
    "        try:\n",
    "            features[i][min(graph.in_degree(i), max_degree-1)] = 1\n",
    "        except:\n",
    "            features[i][0] = 1\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db35280",
   "metadata": {},
   "source": [
    "Train the encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ecc740c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021598339080810547,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 100,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d62ff4cefa449b2b4f7acb74afa964d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "degree_emb = nn.Parameter(torch.FloatTensor(np.random.normal(0, 1, [100, opts.n_hidden])), requires_grad=False)\n",
    "\n",
    "# the features are the node degrees\n",
    "features = degree_bucketing(g, opts, degree_emb)\n",
    "in_feats = features.shape[1]\n",
    "\n",
    "n_classes = labels.max().item() + 1\n",
    "n_edges = g.number_of_edges()\n",
    "\n",
    "\n",
    "# Is this going to be ran on the GPU?\n",
    "if opts.gpu < 0:\n",
    "    cuda = False\n",
    "\n",
    "else:\n",
    "    cuda = True\n",
    "    torch.cuda.set_device(opts.gpu)\n",
    "    features = features.cuda()\n",
    "    in_feats\n",
    "    labels = labels.cuda()\n",
    "\n",
    "    \n",
    "# initialise encoder discriminator duo\n",
    "egi = SubGI(g,\n",
    "            in_feats,\n",
    "            opts.n_hidden,\n",
    "            opts.n_layers,\n",
    "            nn.PReLU(opts.n_hidden),\n",
    "            opts.dropout)\n",
    "\n",
    "if cuda:\n",
    "    egi = egi.cuda()\n",
    "    \n",
    "egi_optimizer = torch.optim.Adam(egi.parameters(),\n",
    "                              lr=opts.dgi_lr,\n",
    "                              weight_decay=opts.weight_decay)\n",
    "\n",
    "# some summary statistics\n",
    "cnt_wait = 0\n",
    "best = 1e9\n",
    "best_t = 0\n",
    "dur = []\n",
    "\n",
    "# hacky hack to make DGL happy \n",
    "g.ndata['features'] = features.to(torch.device('cpu')) \n",
    "\n",
    "# start training\n",
    "for epoch in tqdm(range(opts.n_dgi_epochs)):\n",
    "    \n",
    "    # initialise ego-graph sampler\n",
    "    train_sampler = dgl.contrib.sampling.NeighborSampler(g, 256, 5,\n",
    "                                            neighbor_type='in', num_workers=1,\n",
    "                                            num_hops=opts.n_layers + 1, shuffle=True)\n",
    "    \n",
    "    # Enable training mode for model\n",
    "    egi.train()\n",
    "    \n",
    "    \n",
    "    \n",
    "    if epoch >= 3:\n",
    "        t0 = time.time()\n",
    "\n",
    "    \n",
    "    loss = 0.0\n",
    "    \n",
    "    # train based on features and ego-graphs\n",
    "    for nf in train_sampler:\n",
    "        egi_optimizer.zero_grad()\n",
    "        l = egi(features,nf) # forward propogate\n",
    "        l.backward()\n",
    "        loss += l\n",
    "        egi_optimizer.step()\n",
    "\n",
    "\n",
    "    if loss < best:\n",
    "        best = loss\n",
    "        best_t = epoch\n",
    "        cnt_wait = 0\n",
    "    else:\n",
    "      cnt_wait += 1\n",
    "\n",
    "    if cnt_wait == opts.patience:\n",
    "      print('Early stopping!')\n",
    "      break\n",
    "\n",
    "    if epoch >= 3:\n",
    "      dur.append(time.time() - t0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed917469",
   "metadata": {},
   "source": [
    "Train the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a75303a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How good is the model doing?\n",
    "def evaluate(model, features,labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74b8b3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02084946632385254,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 100,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2048b27013fc4594a2ead4b51dfd9f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = MultiClassifier(opts.n_hidden, n_classes)\n",
    "classifier_optimizer = torch.optim.Adam(classifier.parameters(),\n",
    "                                        lr=opts.classifier_lr,\n",
    "                                        weight_decay=opts.weight_decay)\n",
    "\n",
    "# now that training is done, the discriminator is no longer needed\n",
    "encoder = egi.encoder\n",
    "\n",
    "if cuda:\n",
    "    classifier.cuda()\n",
    "\n",
    "embeds = encoder(features, corrupt=False)\n",
    "    \n",
    "embeds = embeds.detach()\n",
    "    \n",
    "dur = []\n",
    "\n",
    "classifier.train() # enable training mode\n",
    "\n",
    "for epoch in tqdm(range(opts.n_classifier_epochs)):\n",
    "    \n",
    "    if epoch >= 3:\n",
    "        t0 = time.time()\n",
    "\n",
    "    classifier_optimizer.zero_grad() # reset gradient\n",
    "    \n",
    "    preds = classifier(embeds)\n",
    "    \n",
    "    loss = F.nll_loss(preds[train_mask], labels[train_mask])\n",
    "    \n",
    "    loss.backward()\n",
    "    classifier_optimizer.step()\n",
    "\n",
    "    if epoch >= 3:\n",
    "        dur.append(time.time() - t0)\n",
    "        \n",
    "    accuracy = evaluate(classifier, embeds, labels, test_mask)\n",
    "\n",
    "    #print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | Accuracy {:.4f} | \"\n",
    "          #\"ETputs(KTEPS) {:.2f}\".format(epoch, np.mean(dur), loss.item(),\n",
    "           #                             accuracy, n_edges / np.mean(dur) / 1000))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2823f2",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c451b314",
   "metadata": {},
   "source": [
    "Transfer the trained models to the Brazil dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "285eacf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare validation data\n",
    "validation_g,validation_labels = construct_DGL(validation_g,validation_labels)\n",
    "validation_features = degree_bucketing(validation_g,opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3fb2354c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([131, 32])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1eea84a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1190, 32])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "072d5702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DGLGraph(num_nodes=131, num_edges=2279,\n",
       "         ndata_schemes={}\n",
       "         edata_schemes={})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96ee865a",
   "metadata": {},
   "outputs": [
    {
     "ename": "DGLError",
     "evalue": "Expect number of features to match number of nodes (len(u)). Got 131 and 1190 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_199/2801549319.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# use encoder to create node embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrupt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# generate predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1054\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1055\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_199/2439066853.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features, corrupt)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mperm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandperm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1054\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1055\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/mount/notebooks/../../egi/models/subgi.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, h)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mginlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m             \u001b[0;31m# print('batch norm')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1054\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1055\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/dgl/nn/pytorch/conv/ginconv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graph, feat)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mfeat_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_dst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_as_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrcdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat_src\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_u\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reducer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neigh'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mrst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfeat_dst\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'neigh'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/dgl/_deprecate/view.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, val)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzerocopy_from_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_n_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__delitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/dgl/_deprecate/graph.py\u001b[0m in \u001b[0;36mset_n_repr\u001b[0;34m(self, data, u, inplace)\u001b[0m\n\u001b[1;32m   2324\u001b[0m             \u001b[0mnfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnfeats\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2326\u001b[0;31m                 raise DGLError('Expect number of features to match number of nodes (len(u)).'\n\u001b[0m\u001b[1;32m   2327\u001b[0m                                ' Got %d and %d instead.' % (nfeats, num_nodes))\n\u001b[1;32m   2328\u001b[0m         \u001b[0;31m# set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDGLError\u001b[0m: Expect number of features to match number of nodes (len(u)). Got 131 and 1190 instead."
     ]
    }
   ],
   "source": [
    "# use encoder to create node embeddings\n",
    "embeddings = encoder(validation_features, corrupt=False)\n",
    "embeddings = embeddings.detach()\n",
    "\n",
    "# generate predictions\n",
    "predictions = classifier(embeddings)\n",
    "\n",
    "validation_accuracy = evaluate(classifier,embeddings,validation_labels,torch.ones(validation_labels.shape, dtype=torch.bool))\n",
    "\n",
    "print(f\"The model has accuracy {accuracy}, and accuracy {validation_accuracy} when transferred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718d1e80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "name": "EGI Framework overview.ipynb",
  "toc": {
   "base_numbering": "",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "624px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
