{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1be22afe",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2e845a",
   "metadata": {},
   "source": [
    "This notebook considers the use of EGI for link prediction tasks.\n",
    "\n",
    "It largely follows [this example](https://stellargraph.readthedocs.io/en/stable/demos/link-prediction/node2vec-link-prediction.html), but using EGI instead of node2vec for encoding.\n",
    "\n",
    "\n",
    "**The stages to link prediction are:**\n",
    "\n",
    "1. Create and train an encoder to create node embeddings for the source graph.\n",
    "2. Using a binary operator, combine node embeddings to form edge embeddings.\n",
    "3. Train a classifier to distinguish between real and fake edges.\n",
    "\n",
    "\n",
    "For the encoder, we use EGI. Then we create edge embeddings using the hadamard product, and use these to train a SGD classifier.\n",
    "\n",
    "The source dataset is the Cora citation graph. We then consider transferring this to a small subgraph of PubMed citations, generated by randomly sampling edges of the full Pubmed graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b378ac7c",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a835fd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///workspace/mount\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: graphtransferlearning\n",
      "  Building editable for graphtransferlearning (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for graphtransferlearning: filename=graphtransferlearning-0.0.1-0.editable-py3-none-any.whl size=1319 sha256=00fac8f10ebae2841997675471451004c820bc07c65967ccd3db6c04be38a861\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-o2ebaz02/wheels/97/9f/f8/a43530fa3975ba118be1e5dde0c412ea8db4864e54b615e504\n",
      "Successfully built graphtransferlearning\n",
      "Installing collected packages: graphtransferlearning\n",
      "  Attempting uninstall: graphtransferlearning\n",
      "    Found existing installation: graphtransferlearning 0.0.1\n",
      "    Uninstalling graphtransferlearning-0.0.1:\n",
      "      Successfully uninstalled graphtransferlearning-0.0.1\n",
      "Successfully installed graphtransferlearning-0.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -e ..\n",
    "# if the library is not installed yet, restart the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c3a67b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import graphtransferlearning as gtl\n",
    "from graphtransferlearning.features import degree_bucketing\n",
    "\n",
    "import dgl\n",
    "import torch\n",
    "import warnings\n",
    "from random import randint,sample\n",
    "from dgl.data import CoraGraphDataset,PubmedGraphDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2bbc0d",
   "metadata": {},
   "source": [
    "# The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0971e3",
   "metadata": {},
   "source": [
    "For this example, we use the Cora citation graph dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83705288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /root/.dgl/cora_v2.zip from https://data.dgl.ai/dataset/cora_v2.zip...\n",
      "Extracting file to /root/.dgl/cora_v2\n",
      "Finished data loading and preprocessing.\n",
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done saving data into cached files.\n"
     ]
    }
   ],
   "source": [
    "dataset = CoraGraphDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1de1e5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/dgl/data/utils.py:285: UserWarning: Property dataset.graph will be deprecated, please use dataset[0] instead.\n",
      "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n"
     ]
    }
   ],
   "source": [
    "# do things in this not-recommended way as our EGI graph requires a DGLGraphStale not a DGLGraph\n",
    "# see the version 0.5 source code: https://github.com/dmlc/dgl/blob/0.5.x/python/dgl/data/citation_graph.py\n",
    "dgl_graph = dgl.DGLGraphStale()\n",
    "dgl_graph.from_networkx(dataset.graph)\n",
    "dgl_graph.readonly()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0052f4e0",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e564b65",
   "metadata": {},
   "source": [
    "First, an encoder is trained to produce node embeddings for the Cora graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "121b823c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:53<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model parameters to ../models/egi.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings(): # hide all the \"XYZ is deprecated\" messages\n",
    "    warnings.simplefilter('ignore')\n",
    "    encoder = gtl.training.train_egi_encoder(dgl_graph,gpu=0,save_weights_to=\"../models/egi.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee374f63",
   "metadata": {},
   "source": [
    "# Edge embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6c3d93",
   "metadata": {},
   "source": [
    "Next, the node embeddings are converted to edge embeddings. In this case, the nodes at the start and end of the edge are converted into node embeddings, then combined using the hadamard product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bceadd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = degree_bucketing(dgl_graph,32) # the maximum degree must be the same as used in training.\n",
    "                                          # this is usually equal to n_hidden\n",
    "\n",
    "torch.cuda.set_device(torch.device('cuda:0'))\n",
    "features = features.cuda()\n",
    "\n",
    "embs = encoder(features)\n",
    "\n",
    "embs = embs.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f55f04e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_embedding(emb,a,b):\n",
    "    return np.multiply(emb[a].detach().cpu(),emb[b].detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "749a9d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0226, 0.0000, 0.0000, 0.7384, 0.0000, 0.2285, 0.0000, 0.0000,\n",
       "        0.0000, 0.1601, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.4549, 0.0539,\n",
       "        0.0000, 0.0000, 0.4325, 0.2416, 0.0000, 0.0000, 0.0000, 0.0000, 0.2010,\n",
       "        0.0274, 0.0000, 0.0000, 1.3740, 0.0000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_edge_embedding(embs,10,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2089927d",
   "metadata": {},
   "source": [
    "# Training a link prediction classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddffd332",
   "metadata": {},
   "source": [
    "To predict links in a graph, we train a classifier to see if a given edge is real or fake using its embedding as input.\n",
    "\n",
    "To train the classifier, we need both a set of real (positive) edges, and a set of non-existent (negative) edges.\n",
    "\n",
    "**Create these real and fake edges, and convert them into edge embeddings:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ee3c5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/dgl/data/utils.py:285: UserWarning: Property dataset.graph will be deprecated, please use dataset[0] instead.\n",
      "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n"
     ]
    }
   ],
   "source": [
    "positive_edges = list(dataset.graph.edges)\n",
    "nodes = list(dataset.graph.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "455a6364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_negative_edges(edges,nodes,n):\n",
    "    negative_edges = []\n",
    "    for i in range(n):\n",
    "        u = randint(0,n)\n",
    "        v = randint(0,n)\n",
    "        while u == v or (u,v) in edges or (v,u) in edges or v not in nodes or u not in nodes:\n",
    "            u = randint(0,n)\n",
    "            v = randint(0,n)\n",
    "\n",
    "        negative_edges.append((u,v))\n",
    "    \n",
    "    return negative_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0aff728e",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_edges = generate_negative_edges(positive_edges,nodes,len(positive_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f44cff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "values = []\n",
    "\n",
    "for u,v in positive_edges:\n",
    "    edges.append(get_edge_embedding(embs,u,v))\n",
    "    values.append(1)\n",
    "    \n",
    "for u,v in negative_edges:\n",
    "    edges.append(get_edge_embedding(embs,u,v))\n",
    "    values.append(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f0dc308",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_edges,test_edges,train_classes,test_classes = train_test_split(edges,values)\n",
    "train_edges =torch.stack(train_edges) # list of tensors to 3d tensor\n",
    "test_edges =torch.stack(test_edges) # list of tensors to 3d tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23825580",
   "metadata": {},
   "source": [
    "Fit and evaluate the logistic regression model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f410d14e",
   "metadata": {},
   "source": [
    "The classifer needs to support the `partial_fit` API - this allows us to update the parameters according to new data during fine-tuning.\n",
    "\n",
    "The supported models are listed here https://scikit-learn.org/0.15/modules/scaling_strategies.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa9b7be2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier = SGDClassifier(max_iter=1000).fit(train_edges,train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3870d4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cora link predictor has an accuracy score of 0.819439181508147\n"
     ]
    }
   ],
   "source": [
    "print(f\"The Cora link predictor has an accuracy score of \\\n",
    "{classifier.score(test_edges,test_classes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d3874b",
   "metadata": {},
   "source": [
    "# Transfer Learning and fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1d6fe1",
   "metadata": {},
   "source": [
    "A small sub-graph of the pubmed citation graph will be chosen as the transfer target.\n",
    "\n",
    "This graph will have 1000 edges, sampled at random from the larger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0011705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /root/.dgl/pubmed.zip from https://data.dgl.ai/dataset/pubmed.zip...\n",
      "Extracting file to /root/.dgl/pubmed\n",
      "Finished data loading and preprocessing.\n",
      "  NumNodes: 19717\n",
      "  NumEdges: 88651\n",
      "  NumFeats: 500\n",
      "  NumClasses: 3\n",
      "  NumTrainingSamples: 60\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done saving data into cached files.\n",
      "Graph with 1699 nodes and 995 edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/dgl/data/utils.py:285: UserWarning: Property dataset.graph will be deprecated, please use dataset[0] instead.\n",
      "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n"
     ]
    }
   ],
   "source": [
    "transfer_dataset = PubmedGraphDataset()\n",
    "transfer_g = transfer_dataset.graph\n",
    "edge_cnt = 0\n",
    "\n",
    "transfer_g = nx.edge_subgraph(transfer_dataset.graph,sample(transfer_g.edges(),1000)).to_undirected(reciprocal=False)\n",
    "transfer_g = nx.convert_node_labels_to_integers(transfer_g) # renumber nodes to be sequential integers\n",
    "print(transfer_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abae70f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dgl for EGI training\n",
    "transfer_g_dgl = dgl.DGLGraphStale()\n",
    "transfer_g_dgl.from_networkx(transfer_g)\n",
    "\n",
    "transfer_g_dgl.readonly()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6c7ed1",
   "metadata": {},
   "source": [
    "## Fine-tuning the embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "257f1ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.8/site-packages/dgl/base.py:45: DGLWarning: dgl.contrib.sampling.NeighborSampler is deprecated starting from v0.5. Please read our guide<link> for how to use the new sampling APIs.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "/opt/conda/lib/python3.8/site-packages/dgl/base.py:45: DGLWarning: NodeFlow APIs are deprecated starting from v0.5. Please read our guide<link> for how to use the new sampling APIs.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 100/100 [00:40<00:00,  2.45it/s]\n"
     ]
    }
   ],
   "source": [
    "transfer_encoder = gtl.training.train_egi_encoder(transfer_g_dgl,gpu=0,pre_train=\"../models/egi.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005c1a23",
   "metadata": {},
   "source": [
    "## Fine-tuning the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c03332",
   "metadata": {},
   "source": [
    "The above steps are repeated, but for the transfer dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15dad666",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = degree_bucketing(transfer_g_dgl,32)\n",
    "\n",
    "torch.cuda.set_device(torch.device('cuda:0'))\n",
    "features = features.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "418342cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1699, 32])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs = transfer_encoder(features)\n",
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5156dd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_edges = list(transfer_g.edges)\n",
    "nodes = list(transfer_g.nodes)\n",
    "negative_edges = generate_negative_edges(positive_edges,nodes,len(positive_edges)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a197503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "values = []\n",
    "\n",
    "for u,v in positive_edges:\n",
    "    edges.append(get_edge_embedding(embs,u,v))\n",
    "    values.append(1)\n",
    "    \n",
    "for u,v in negative_edges:\n",
    "    edges.append(get_edge_embedding(embs,u,v))\n",
    "    values.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8c35597",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edges,test_edges,train_classes,test_classes = train_test_split(edges,values)\n",
    "train_edges =torch.stack(train_edges) # list of tensors to 3d tensor\n",
    "test_edges =torch.stack(test_edges) # list of tensors to 3d tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efd97c4",
   "metadata": {},
   "source": [
    "Note that we use *partial fit* to train the classifier instead of *fit*. This updates the current weights of the classifier instead of overwriting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1bd7242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The link predictor has an accuracy score of 0.748995983935743\n"
     ]
    }
   ],
   "source": [
    "classifier2 = classifier.partial_fit(train_edges,train_classes)\n",
    "print(f\"The link predictor has an accuracy score of \\\n",
    "{classifier2.score(test_edges,test_classes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833d0a55",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b651fa",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- model tuning (epochs in fine-tuning, k, etc)\n",
    "- comparisions of using:\n",
    "    - finetuned pubmed model\n",
    "    - cobra model on pubmed\n",
    "    - a model trained only on pubmed\n",
    "- target graph size vs accuracy - (this is adjustable above)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c6e092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
